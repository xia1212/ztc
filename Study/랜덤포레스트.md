# 랜덤포레스트 모델

### 개별 트리 모델의 단점의 해결방안으로 랜덤 포레스트 모델

나무의 최종노드 개수를 늘리면 training error는 거의 0으로 만들 수가 있는데, 그렇게 되면 과적합이 발생  

Large Variance 생긴다는 것은 현재 우리가 가지고 있는 training 데이터의 정확도는 좋으나, 미래에 올 testing 데이터에 대한 예측정확도에 대해서는 장담할 수 없는 위험도라고 할 수 있음

이러한 해결방안으로 랜덤 포레스트 모델이 있음

랜덤 포레스트 배경은 앙상블 모델의 한 예라고 볼 수 있음

## 랜덤 포레스트 배경 - 앙상블

- 앙상블 : 여러 모델들의 예측을 다수결 법칙 또는 평균을 이용해 통합하여 예측 정확성을 향상시키는 방법을 말함.

![image](https://user-images.githubusercontent.com/79880336/112155346-90273080-8c28-11eb-965a-703e478a9313.png)

- 오류율

![image](https://user-images.githubusercontent.com/79880336/112155488-b1881c80-8c28-11eb-8c74-1b9e153dd8e9.png)

(x축은 오류율을 나타냄. 거기에서 0.5를 기준으로 오른쪽은 앙상블의 오류율이 좀 높아 짐.

두 개의 class로 나누는 것이라면, 앙상블의 효과는 0.5보다 작은 쪽에서 얻을 수 있음

파란 색 선을 보면 0.5를 기준으로 보면 내려가는 것을 볼 수 있음)

- 앙상블 모델의 베이스 모델로서 의사결정나무를 사용하는 것이 랜덤포레스트

![image](https://user-images.githubusercontent.com/79880336/112155740-f0b66d80-8c28-11eb-9989-3fe7a89088b4.png)

## 랜덤 포레스트 개요

- T의 결과를 잘 종합하여 최종 예측 총합을 보는 것을 랜덤 포레스트의 개요

![image](https://user-images.githubusercontent.com/79880336/112155952-252a2980-8c29-11eb-8445-404449059ad6.png)

## Bagging (Bootstrap Aggregating)

![image](https://user-images.githubusercontent.com/79880336/112156219-602c5d00-8c29-11eb-98e1-edb406fba039.png)

Bagging은 Bootstrap Aggregating 의 약어이다.

1. 처음에 원래의 데이터(observations)가 있고 Bootstrap 방식으로 여러개의 training subset을 형성함.
2. 각각의 의사결정나무를 만들고, 
3. 각각의 결과들을 통해서 
4. 최종적으로 예측한다. 

Bootstrapping이란?
sampling 기법이고 추출하는 것이다. 

중요한 것은 첫째, 복원추출을 한다. 한번 뽑으면 다시 집어 넣는 것이다. 

둘째, 원래의 데이터의 수 만큼의 크기를 갖도록 샘플링하는 것이다. 

두 가지를 충족해야지 부스트랩 샘플링이라고 부름.  

![image](https://user-images.githubusercontent.com/79880336/112156457-9b2e9080-8c29-11eb-958a-a1a5b3ad84b0.png)

1. 부스트랩셋을 설정한다.
2. 원래의 데이터셋은 x와 y가 각 쌍으로 되어 있음
3. 총 관측치의 갯수는 10개임
4. 복원추출하는 것임
5. 총 B번 시행함

복원추출하는 것이라서 첫번째는 X7이 세번, X1이 선택되지 않음
두번째는 X1이 두번 선택이 되었지만 X5는 선택이 되지 않음 (들어 갈 수도, 들어가지 않을 수도 있음) 
원래 데이터가 10개가 있다면 꼭 10개씩 샘플링해야 된다는 것임
이것이 부스트랩의 특징임
