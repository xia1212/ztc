### 4장 로지스틱 회귀모델


## 로직스틱 회귀모델 발생배경

![image](https://user-images.githubusercontent.com/79880336/110303310-95d42200-803d-11eb-8e37-5b39332061c0.png)

기존까지의 선형회귀모델에서는 수치형 변수가 Y값에 있었던 데에 반해, 
Y값에 범주형 변수가 오게 될 경우에는 조금 다른 방법으로 접근해야 할 필요성이 생겼다. 
왜냐하면 기존의 선형회귀모델에서는 오차항이 정규분포를 따른다든가 하는 몇 가지 제약조건이 전제되어야 했는데, 
이러한 범주형 데이터에서는 그러한 제약조건에 부합하지 않는 경우도 종종 발생하기 때문이다. 

그래서 새로운 분석 방법인 로지스틱 회귀모델은 새로운 관측치가 왔을 때 이를 기존 범주 중 하나로 예측하게 한다.
이를 가리켜 범주예측 이라고 한다.

범주예측에는
- 제품이 불량인지 양품인지
- 고객이 이탈고객인지 잔류고객인지
- 카드 거래가 정상인지 사기인지
- 내원 고객이 질병이 있는지 없는지​
등과 같이 결과값이 범주로 되어 있는 경우이다.

이론적인 배경에 대해 설명해보면

![image](https://user-images.githubusercontent.com/79880336/110303443-bbf9c200-803d-11eb-87f4-b82b288e6628.png)


## 로직스틱 회귀모델의 형태
아래와 같이 질병유무 데이터의 Y값이 0과 1의 범주형 변수로 주어질 경우

![image](https://user-images.githubusercontent.com/79880336/110303539-d7fd6380-803d-11eb-9547-60bfb903c91a.png)

![image](https://user-images.githubusercontent.com/79880336/110303552-dc298100-803d-11eb-8603-583e59210145.png)

![image](https://user-images.githubusercontent.com/79880336/110303564-df247180-803d-11eb-8f20-e5027ad8d1d2.png)

위 raw data를 범주에 맞게 정리해 보면 위와 같은 표를 구할 수 있다.
이를 도식화하면 아래의 그래프로 표시된다.

![image](https://user-images.githubusercontent.com/79880336/110303612-ec416080-803d-11eb-9ed3-9a4e7988c728.png)

이는 선형으로 표시할 수 있으나, 
조금 더 정확하게 표기한다면 약간의 S자 형태의 유선형을 띄고 있는 그래프라고 볼 수 있다. 
이러한 모양을 나타낼 수 있는 함수식은 아래와 같다.

![image](https://user-images.githubusercontent.com/79880336/110303686-0418e480-803e-11eb-970b-997dfa400d77.png)

위의 수식을 로지스틱(Logistic) 함수 또는 시그모이드(Sigmoid) 함수라 부른다. 

![image](https://user-images.githubusercontent.com/79880336/110303710-0ed37980-803e-11eb-9fd7-ad86f0afd0b1.png)

- 로지스틱 함수는 0과 1 사이의 값을 가지게 된다.
- 로지스틱 함수는 인풋 값에 대해 단조증가/단조감소 하게 된다. 단조증가란 위 그래프처럼 x₁＜x₂면 반드시 f(x₁)＜f(x₂)로 되는 경우를 말한다.
- 로지스틱 함수는 미분 결과를 아래와 같은 함수로 표현 가능한데, 이는 Gradient Descent Method에서 유용하게 사용한다.

![image](https://user-images.githubusercontent.com/79880336/110303754-1c88ff00-803e-11eb-94ac-ff0ea01b322c.png)

그래서 이를 정리하여 로지스틱 함수를 만들 수 있다.

우리가 앞서 말한 것처럼 Y의 기댓값은 X가 특정 범주의 값일 떄 Y가 1일 때의 확률과 같다.

입력변수가 1개일 때의 로지스틱 회귀모델을 가리켜 단순로지스틱 회귀모델이라 부른다.

![image](https://user-images.githubusercontent.com/79880336/110303782-2579d080-803e-11eb-9f78-684c24e2f838.png)

이는 관측치 x가 범주 1에 속할 확률과 같다. 
여기서, 파라미터를 해석하는 방법이 중요한데 beta 1은 선형회귀모델에서는 단순하고 직관적이었으나 
로지스틱 회귀모델의 경우에는 비선형의 형태를 띄고 있으므로 직관적이지 못하다. 
따라서 이를 보완하기 위해 승산(Odd) 이라는 개념을 도입하게 되었다.

## 승산(Odds)

승산이란, 성공 확률을 p로 정의할 때 실패 대비 성공 확률 비율을 가리킨다.

![image](https://user-images.githubusercontent.com/79880336/110303889-493d1680-803e-11eb-8341-c58663c8e849.png)

이를 로지스틱 회귀모델에 맞게 변형해서 다시 풀어 쓰자면, Odds는 범주 0에 속할 확률 대비 범주 1에 속할 확률을 가리킨다. 이렇게 구해진 Odds에 Log를 취하면 아래와 같이 수식이 정리된다.

![image](https://user-images.githubusercontent.com/79880336/110303939-565a0580-803e-11eb-8e89-59ee38d0b4d3.png)

이를 통해 Odds를 활용하여 복잡한 로지스틱 함수 형태를 선형결합의 형태로 바꿀 수 있게 된다. 
이러한 형태의 변환을 로짓 변환(Logit Transform)이라 한다. 
이러한 log(Odds)가 선형회귀분석과 동일한 레벨의 직관성을 띈다고 할 수는 없지만, 
이전의 로지스틱 함수에 비해서는 굉장히 직관적이기 때문에 유용하게 활용할 수 있게 된다.

![image](https://user-images.githubusercontent.com/79880336/110304008-6a9e0280-803e-11eb-9303-f1d7637ae6fa.png)

![image](https://user-images.githubusercontent.com/79880336/110304040-75589780-803e-11eb-9b1a-2a4b74d0e26d.png)


위의 그래프에서 성공 확률이 0.5가 되면 log(Odds)의 값은 
Odds=0.5/(1-0.5)=1이므로 log1이 되고 이는 0과 같아진다. 

반면 성공확률이 1이 되면 log(Odds)의 값은
Odds = 1/(1-1) = infinite이므로 무한대가 된다.

또한 성공 확률이 0이 되면 log(Odds)의 값은
dds = 0/(1-0) = 0이므로 -infinite로 수렴하게 된다.
