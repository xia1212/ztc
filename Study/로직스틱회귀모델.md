### 4장 로지스틱 회귀모델


## 로직스틱 회귀모델 발생배경

![image](https://user-images.githubusercontent.com/79880336/110303310-95d42200-803d-11eb-8e37-5b39332061c0.png)

선형회귀모델에서는 수치형 변수가 Y값에 있었고
Y값에 범주형 변수가 오게 될 경우에는 조금 다른 방법으로 접근해야 할 필요성이 생겼다.
왜냐하면 기존의 선형회귀모델에서는 오차항이 정규분포를 따른다든가 하는 몇 가지 제약조건이 전제되야하는데
범주형 데이터에서는 제약조건에 부합하지 않는 경우도 종종 발생하기 때문이다. 

- 로지스틱 회귀모델 사용
 새로운 관측치가 왔을 때 이를 기존 범주 중 하나로 예측하게 한다. (범주예측)
 - 범주예측에는
    - 제품이 불량인지 양품인지
    - 고객이 이탈고객인지 잔류고객인지
    - 카드 거래가 정상인지 사기인지
    - 내원 고객이 질병이 있는지 없는지
    등과 같이 결과값이 범주로 되어 있는 경우이다.

이론적인 배경에 대해 설명해보면

![image](https://user-images.githubusercontent.com/79880336/110327748-ba3ff680-805d-11eb-8b9b-c147885f285d.png)

## 로직스틱 회귀모델의 형태

- 출력변수가 연속형이 아닌 이진범주형 질병유무?
아래와 같이 질병유무 데이터의 Y값이 0과 1의 범주형 변수로 주어질 경우

![image](https://user-images.githubusercontent.com/79880336/110303539-d7fd6380-803d-11eb-9547-60bfb903c91a.png)

- 두 변수 사이의 관계식은 선형?

![image](https://user-images.githubusercontent.com/79880336/110303552-dc298100-803d-11eb-8603-583e59210145.png)

![image](https://user-images.githubusercontent.com/79880336/110303564-df247180-803d-11eb-8f20-e5027ad8d1d2.png)

위 raw data를 범주에 맞게 정리해 보면 위와 같은 표를 구할 수 있다.
이를 도식화하면 아래의 그래프로 표시된다.

![image](https://user-images.githubusercontent.com/79880336/110303612-ec416080-803d-11eb-9ed3-9a4e7988c728.png)

이는 선형으로 표시할 수 있지만 더 정확하게 표기한다면 약간의 S자 형태의 유선형을 띄고 있는 그래프라고 볼 수 있다. 

이러한 모양을 나타낼 수 있는 함수식은 아래와 같다.

![image](https://user-images.githubusercontent.com/79880336/110303686-0418e480-803e-11eb-970b-997dfa400d77.png)

위의 수식을 로지스틱(Logistic) 함수 또는 시그모이드(Sigmoid) 함수라 부른다. 

![image](https://user-images.githubusercontent.com/79880336/110328252-74cff900-805e-11eb-9c3b-9c0c0cb8c045.png)

- 로지스틱 함수는 0과 1 사이의 값을 가지게 된다.
- 로지스틱 함수는 인풋 값에 대해 단조증가/단조감소 하게 된다. 단조증가란 위 그래프처럼 x₁＜x₂면 반드시 f(x₁)＜f(x₂)로 되는 경우를 말한다.
- 로지스틱 함수는 미분 결과를 아래와 같은 함수로 표현 가능한데, 이는 Gradient Descent Method에서 유용하게 사용한다.

![image](https://user-images.githubusercontent.com/79880336/110328425-b06ac300-805e-11eb-8172-0b26dadfb74a.png)

그래서 이를 정리하여 로지스틱 함수를 만들 수 있다.

우리가 앞서 말한 것처럼 Y의 기댓값은 X가 특정 범주의 값일 떄 Y가 1일 때의 확률과 같다.

입력변수가 1개일 때의 로지스틱 회귀모델을 가리켜 단순로지스틱 회귀모델이라 부른다.

![image](https://user-images.githubusercontent.com/79880336/110328540-d001eb80-805e-11eb-84de-2c136530248a.png)

관측치 x가 범주 1에 속할 확률과 같다. 
파라미터를 해석하는 방법이 중요한데 beta1은 선형회귀모델에서는 단순하고 직관적이었으나 
로지스틱 회귀모델의 경우에는 비선형의 형태를 띄고 있으므로 직관적이지 못하다. 
따라서 이를 보완하기 위해 승산(Odd) 이라는 개념을 도입하게 되었다.

## 승산(Odds)

승산이란, 성공 확률을 p로 정의할 때 실패 대비 성공 확률 비율을 가리킨다.

![image](https://user-images.githubusercontent.com/79880336/110303889-493d1680-803e-11eb-8341-c58663c8e849.png)

이를 로지스틱 회귀모델에 맞게 변형해서 다시 풀어 쓰자면, Odds는 범주 0에 속할 확률 대비 범주 1에 속할 확률을 가리킨다. 이렇게 구해진 Odds에 Log를 취하면 아래와 같이 수식이 정리된다.

![image](https://user-images.githubusercontent.com/79880336/110303939-565a0580-803e-11eb-8e89-59ee38d0b4d3.png)

이를 통해 Odds를 활용하여 복잡한 로지스틱 함수 형태를 선형결합의 형태로 바꿀 수 있게 된다. 
이러한 형태의 변환을 로짓 변환(Logit Transform)이라 한다. 
이러한 log(Odds)가 선형회귀분석과 동일한 레벨의 직관성을 띈다고 할 수는 없지만, 
이전의 로지스틱 함수에 비해서는 굉장히 직관적이기 때문에 유용하게 활용할 수 있게 된다.

![image](https://user-images.githubusercontent.com/79880336/110304008-6a9e0280-803e-11eb-9303-f1d7637ae6fa.png)

![image](https://user-images.githubusercontent.com/79880336/110304040-75589780-803e-11eb-9b1a-2a4b74d0e26d.png)


위의 그래프에서 성공 확률이 0.5가 되면 log(Odds)의 값은 
Odds=0.5/(1-0.5)=1이므로 log1이 되고 이는 0과 같아진다. 

반면 성공확률이 1이 되면 log(Odds)의 값은
Odds = 1/(1-1) = infinite이므로 무한대가 된다.

또한 성공 확률이 0이 되면 log(Odds)의 값은
dds = 0/(1-0) = 0이므로 -infinite로 수렴하게 된다.

## 다중 로직스틱 회귀모델

![image](https://user-images.githubusercontent.com/79880336/110304271-b94b9c80-803e-11eb-8276-eda27acd5a6b.png)

## 파라미터 추정
- 로지스틱 회귀모델 학습 : 최대 우도 추정법(Maximum Likelihood Estimation)


- 위 로그 우도함수가 최대가 되는 파라미터 beta 결정
- 로그 우도함수는 파라미터 beta에 대해 비선형이므로 선형회귀모델과 같이 명시적인 해가 존재하지 않음
- Iterative reweight least square, Conjugate gradient, Newton's method 등의 수치 최적화 알고리즘을 이용해 해를 구함

Cross Entropy : 두 확률분포 (p(x), q(x))의 차이, 음의 로그 우도함수의 기대값

![image](https://user-images.githubusercontent.com/79880336/110304418-eef08580-803e-11eb-8d6a-e1d1cccd9191.png)

로그 우도함수의 최대 - 입력 분포 p(x)와 파라미터가 주어졌을 때, 출력분포 q(x)의 확률을 최대
Cross Entropy의 최소 - 입력 분포 p(x)와 출력 분포 q(x)의 차이를 최소

![image](https://user-images.githubusercontent.com/79880336/110304463-fc0d7480-803e-11eb-8c5c-b0ca93894c32.png)

## 로지스틱 회귀모델 - 결과 및 해석

![image](https://user-images.githubusercontent.com/79880336/110304526-0f204480-803f-11eb-8947-021c1d171e64.png)

선형회귀모델 : 입력변수가 1단위 증가할 때 출력변수의 변화량
로지스틱 회귀모델 : 입력변수가 1단위 증가할 때 log Odd의 변화량

# 승산 비율 (Odds Ratio)

![image](https://user-images.githubusercontent.com/79880336/110304610-24956e80-803f-11eb-9edf-5e7350f35d30.png)

- 나머지 입력변수는 모두 고정시킨 상태에서 한 변수를 1단위 증가시켰을 때 변화하는 Odds의 비율
- x1이 1단위 증가하면 성공에 대한 승산비율이 e^beta1 만큼 변화함
- 회귀 계수가 양수 -> 성공확률 증가(성공확률 >= 1)
- 회귀 계수가 음수 -> 성공확률 감소(0 <= 성공확률 < 1)

![image](https://user-images.githubusercontent.com/79880336/110325801-23723a80-805b-11eb-90ba-e2fe791e8b6a.png)

Coefficient(로지스틱 회귀계수, 추정된 파라미터 값)
- 해당 변수가 1단위 증가할 때 Log Odds의 변화량
- 양수이면 성공확률과 양의 상관관계, 음수이면 성공확률과 음의 상관관계

Std. Error(추정 파라미터의 표준편차):
- 추정 파라미터의 신뢰구간 (구간추정)을 구축할 때 사용

p-value
- 해당 변수가 통계적으로 유의미한지 여부를 알려주는 지표
- 해당 파라미터 값이 0인지 여부를 통계적으로 판단(가설 검정)

Odds(Odds Ratio)
- 나머지 입력변수는 모두 고정시킨 상태에서 한 변수를 1단위 증가시켰을 때 변화하는 Odds(성공확률)의 비율
- ex.) Experience = 1.058 -> 경험이 1년 더 많으면 대출 확률이 1.058배 증가
