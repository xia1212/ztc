## 단어 벡터 변환 (Word2Vec)

- Can text be input in deep learning? NO (텍스트 안됨)

- Can number be input in deep learning? Yes (숫자 가능)

- What is Enconing? Convert text to number

- What is One Hot Encoding? 
: Conver text to vector

- One Hot Encoding 단점
: 유사도가 없다 (One Hot Encondig doesn't have similarity)

- Embedding (언어의 벡터화)
: Embedding is dense vector with similarity 

- Word2Vec 은 Embedding 중 하나

## WMD 문서 유사도 구하기 (Word mover's distance)

- What is WMD?
1. Novel distance function between text documents
2. So you can get document similarity with WMD

- How WMD can give us document similarity? 
: Word2Vec이 베이스로 사용 (Using the Euclidean distance of Word2Vec)

- What is Worde2Vec?
1. Word Embedding
2. Word similarity comes from the word's neighbor words
3. You also can easily download pre-trained word2vec
4. GoogleNews-vectors-negative300.bin.gz


## [딥러닝 기계번역] 시퀀스 투 시퀀스 + 어텐션

- English and Korean has different word order
  - English = Sebject / Verb / Object , Korean = Sebject / Object / Verb

- How about sequence of words translation? Use RNN

- We call it Encoder Decoder Architecture or Sequence to Sequence model

- Encoder 역할 : Encoder reads and encodes a source sentence into a fixed length vector
- Decoder 역할 : Decoder then outputs a translation from the encoded vector (context vector)

- Encoder -> Context vector -> Decoder (Context vector = Fixed size)
  - 단점 : 문장이 짧으면 상관없지만, 문장이 길어지만 문제가 된다

- 리서치 페이퍼

- 장점
1. Encode info into sequence of vectors not in a single context vector (다양하게 context vector 생성)
2. chooses a subset o these vectors adaptively while decoding the translation
